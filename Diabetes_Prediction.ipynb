{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "from sklearn.preprocessing import Binarizer,Normalizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "data = pd.read_csv(\"D:\\\\dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pregnancies_binarized   Glucose  BloodPressure  SkinThickness   Insulin  \\\n",
      "0                        0  0.512563       0.285714       0.147130  0.079085   \n",
      "1                        1  0.542714       0.387755       0.271739  0.050481   \n",
      "2                        1  0.557789       0.387755       0.147130  0.079085   \n",
      "3                        0  0.688442       0.448980       0.076087  0.161058   \n",
      "4                        1  0.487437       0.469388       0.086957  0.079085   \n",
      "5                        1  0.472362       0.418367       0.163043  0.079085   \n",
      "6                        1  0.562814       0.520408       0.271739  0.079085   \n",
      "7                        1  0.542714       0.408163       0.147130  0.079085   \n",
      "8                        1  0.447236       0.428571       0.173913  0.096154   \n",
      "9                        1  0.527638       0.346939       0.147130  0.079085   \n",
      "10                       1  0.457286       0.408163       0.184783  0.079085   \n",
      "11                       1  0.582915       0.469388       0.228261  0.079085   \n",
      "12                       0  0.628141       0.448980       0.147130  0.079085   \n",
      "13                       0  0.698492       0.387755       0.108696  0.235577   \n",
      "14                       1  0.497487       0.530612       0.086957  0.044471   \n",
      "15                       1  0.366834       0.265306       0.032609  0.079085   \n",
      "16                       0  0.507538       0.408163       0.108696  0.079085   \n",
      "17                       1  0.718593       0.510204       0.163043  0.056490   \n",
      "18                       1  0.402010       0.316327       0.147130  0.079085   \n",
      "19                       0  0.628141       0.734694       0.147130  0.079085   \n",
      "20                       1  0.653266       0.734694       0.147130  0.079085   \n",
      "21                       1  0.482412       0.408163       0.217391  0.087740   \n",
      "22                       1  0.572864       0.428571       0.315217  0.223558   \n",
      "23                       1  0.487437       0.408163       0.130435  0.081731   \n",
      "24                       1  0.000000       0.510204       0.141304  0.010817   \n",
      "25                       1  0.422111       0.460255       0.147130  0.079085   \n",
      "26                       1  0.587940       0.673469       0.130435  0.068510   \n",
      "27                       0  0.472362       0.469388       0.217391  0.121394   \n",
      "28                       0  0.673367       0.346939       0.141304  0.332933   \n",
      "29                       1  0.502513       0.408163       0.173913  0.079085   \n",
      "..                     ...       ...            ...            ...       ...   \n",
      "738                      1  0.547739       0.520408       0.206522  0.079085   \n",
      "739                      1  0.648241       0.673469       0.000000  0.375000   \n",
      "740                      1  0.909548       0.448980       0.315217  0.578125   \n",
      "741                      1  0.733668       0.693878       0.147130  0.079085   \n",
      "742                      1  0.713568       0.367347       0.282609  0.211538   \n",
      "743                      1  0.608040       0.551020       0.108696  0.079085   \n",
      "744                      1  0.989950       0.469388       1.000000  0.079085   \n",
      "745                      1  0.678392       0.306122       0.147130  0.079085   \n",
      "746                      0  0.527638       0.612245       0.147130  0.079085   \n",
      "747                      1  0.507538       0.530612       0.445652  0.199519   \n",
      "748                      1  0.713568       0.571429       0.086957  0.079085   \n",
      "749                      1  0.793970       0.469388       0.147130  0.079085   \n",
      "750                      1  0.663317       0.632653       0.260870  0.079085   \n",
      "751                      1  0.603015       0.551020       0.147130  0.079085   \n",
      "752                      1  0.738693       0.551020       0.147130  0.079085   \n",
      "753                      0  0.809045       0.265306       0.147130  0.079085   \n",
      "754                      1  0.517588       0.857143       0.326087  0.079085   \n",
      "755                      1  0.572864       0.653061       0.147130  0.079085   \n",
      "756                      1  0.954774       0.693878       0.147130  0.079085   \n",
      "757                      1  0.834171       0.510204       0.147130  0.079085   \n",
      "758                      1  0.793970       0.673469       0.147130  0.079085   \n",
      "759                      1  0.733668       0.551020       0.147130  0.079085   \n",
      "760                      1  0.974874       0.571429       0.147130  0.079085   \n",
      "761                      0  0.286432       0.367347       0.147130  0.079085   \n",
      "762                      1  0.457286       0.591837       0.147130  0.079085   \n",
      "763                      1  0.663317       0.571429       0.147130  0.079085   \n",
      "764                      1  0.683417       0.591837       0.147130  0.079085   \n",
      "765                      1  0.728643       0.591837       0.119565  0.079085   \n",
      "766                      1  0.597990       0.460255       0.147130  0.079085   \n",
      "767                      1  0.673367       0.510204       0.282609  0.055288   \n",
      "\n",
      "          BMI  DiabetesPedigreeFunction       Age  Outcome  cluster_0_1  \\\n",
      "0    0.141104                  0.000000  0.000000        0            0   \n",
      "1    0.143149                  0.021349  0.000000        0            0   \n",
      "2    0.089980                  0.027327  0.000000        0            0   \n",
      "3    0.134969                  0.027754  0.000000        0            0   \n",
      "4    0.000000                  0.029462  0.000000        0            0   \n",
      "5    0.132924                  0.029889  0.000000        0            0   \n",
      "6    0.357873                  0.029889  0.000000        0            0   \n",
      "7    0.257669                  0.034159  0.000000        0            0   \n",
      "8    0.202454                  0.038002  0.000000        0            0   \n",
      "9    0.124744                  0.046541  0.000000        0            0   \n",
      "10   0.224949                  0.048676  0.000000        0            0   \n",
      "11   0.188139                  0.053800  0.000000        0            0   \n",
      "12   0.132924                  0.054654  0.000000        0            0   \n",
      "13   0.079755                  0.055081  0.000000        0            0   \n",
      "14   0.102249                  0.061913  0.000000        0            0   \n",
      "15   0.098160                  0.072588  0.000000        0            0   \n",
      "16   0.057260                  0.074295  0.000000        0            0   \n",
      "17   0.163599                  0.076003  0.000000        0            0   \n",
      "18   0.018405                  0.076857  0.000000        0            0   \n",
      "19   0.087935                  0.078565  0.000000        0            0   \n",
      "20   0.089980                  0.081127  0.000000        0            0   \n",
      "21   0.306748                  0.090094  0.000000        0            0   \n",
      "22   0.406953                  0.090094  0.000000        0            0   \n",
      "23   0.000000                  0.094364  0.000000        0            0   \n",
      "24   0.194274                  0.094364  0.000000        0            0   \n",
      "25   0.282065                  0.096499  0.000000        0            0   \n",
      "26   0.143149                  0.100342  0.000000        0            0   \n",
      "27   0.517382                  0.114859  0.000000        0            0   \n",
      "28   0.167689                  0.116994  0.000000        0            0   \n",
      "29   0.235174                  0.123826  0.000000        0            0   \n",
      "..        ...                       ...       ...      ...          ...   \n",
      "738  0.364008                  0.199829  0.650000        0            1   \n",
      "739  0.028630                  0.215201  0.650000        0            1   \n",
      "740  0.243354                  0.229291  0.650000        1            1   \n",
      "741  0.265849                  0.196840  0.666667        1            1   \n",
      "742  0.216769                  0.260034  0.666667        0            1   \n",
      "743  0.169734                  0.077284  0.683333        0            1   \n",
      "744  0.337423                  0.212212  0.683333        1            1   \n",
      "745  0.173824                  0.260034  0.683333        0            1   \n",
      "746  0.198364                  0.283091  0.683333        1            1   \n",
      "747  0.300613                  0.039710  0.700000        0            1   \n",
      "748  0.290389                  0.052092  0.700000        0            1   \n",
      "749  0.237219                  0.055081  0.700000        0            1   \n",
      "750  0.200409                  0.145602  0.700000        0            1   \n",
      "751  0.139059                  0.141332  0.716667        0            1   \n",
      "752  0.316973                  0.059778  0.733333        0            1   \n",
      "753  0.075665                  0.075149  0.733333        0            1   \n",
      "754  0.429448                  0.096926  0.733333        0            1   \n",
      "755  0.196319                  0.072161  0.750000        0            1   \n",
      "756  0.353783                  0.085397  0.750000        1            1   \n",
      "757  0.171779                  0.096499  0.750000        0            1   \n",
      "758  0.274029                  0.310418  0.750000        1            1   \n",
      "759  0.415133                  0.188728  0.766667        1            1   \n",
      "760  0.161554                  0.201964  0.766667        0            1   \n",
      "761  0.071575                  0.280529  0.766667        0            1   \n",
      "762  0.355828                  0.217336  0.783333        0            1   \n",
      "763  0.175869                  0.046114  0.800000        0            1   \n",
      "764  0.282065                  0.239966  0.800000        0            1   \n",
      "765  0.292434                  0.067037  0.816667        1            1   \n",
      "766  0.028630                  0.321947  0.850000        0            1   \n",
      "767  0.157464                  0.163108  1.000000        0            1   \n",
      "\n",
      "      cluster  \n",
      "0    cluster1  \n",
      "1    cluster1  \n",
      "2    cluster1  \n",
      "3    cluster1  \n",
      "4    cluster1  \n",
      "5    cluster1  \n",
      "6    cluster1  \n",
      "7    cluster1  \n",
      "8    cluster1  \n",
      "9    cluster1  \n",
      "10   cluster1  \n",
      "11   cluster1  \n",
      "12   cluster1  \n",
      "13   cluster1  \n",
      "14   cluster1  \n",
      "15   cluster1  \n",
      "16   cluster1  \n",
      "17   cluster1  \n",
      "18   cluster1  \n",
      "19   cluster1  \n",
      "20   cluster1  \n",
      "21   cluster1  \n",
      "22   cluster1  \n",
      "23   cluster1  \n",
      "24   cluster1  \n",
      "25   cluster1  \n",
      "26   cluster1  \n",
      "27   cluster1  \n",
      "28   cluster1  \n",
      "29   cluster1  \n",
      "..        ...  \n",
      "738  cluster2  \n",
      "739  cluster2  \n",
      "740  cluster2  \n",
      "741  cluster2  \n",
      "742  cluster2  \n",
      "743  cluster2  \n",
      "744  cluster2  \n",
      "745  cluster2  \n",
      "746  cluster2  \n",
      "747  cluster2  \n",
      "748  cluster2  \n",
      "749  cluster2  \n",
      "750  cluster2  \n",
      "751  cluster2  \n",
      "752  cluster2  \n",
      "753  cluster2  \n",
      "754  cluster2  \n",
      "755  cluster2  \n",
      "756  cluster2  \n",
      "757  cluster2  \n",
      "758  cluster2  \n",
      "759  cluster2  \n",
      "760  cluster2  \n",
      "761  cluster2  \n",
      "762  cluster2  \n",
      "763  cluster2  \n",
      "764  cluster2  \n",
      "765  cluster2  \n",
      "766  cluster2  \n",
      "767  cluster2  \n",
      "\n",
      "[768 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#This is the data after K-means clustering\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting preprocessed data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Pregnancies_binarized','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]\n",
    "y = data['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=data['Outcome'],test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes on preporcessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 192 points : 51, performance 73.44%\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "      .format(\n",
    "          X_test.shape[0],\n",
    "          (y_test != y_pred).sum(),\n",
    "          100*(1-(y_test!= y_pred).sum()/X_test.shape[0])\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression on preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.766\n",
      "Test set score: 0.745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing accuracy after applying only K-means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72265625\n",
      "[[371 129]\n",
      " [ 84 184]]\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "print(accuracy_score(data['Outcome'], data['cluster_0_1']))\n",
    "print(confusion_matrix(data['Outcome'], data['cluster_0_1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling correctly classified data after K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "new_list = list()\n",
    "newDF = pd.DataFrame()\n",
    "for (idx,row) in data.iterrows():\n",
    "    if row.Outcome == row.cluster_0_1:\n",
    "        new_list.append(row)\n",
    "        #print(new_list)\n",
    "        d = pd.DataFrame(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the correctly classified data\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying logistic regression on Correctly classified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data into train and test for logistic regression\n",
    "X = d[['Pregnancies_binarized','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age']]\n",
    "y = d['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=d['Outcome'],test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.962\n",
      "Test set score: 0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[93  0]\n",
      " [ 6 40]]\n",
      "0.9568345323741008\n"
     ]
    }
   ],
   "source": [
    "#Printing the confusion matrix and final accuracy score\n",
    "print(confusion_matrix(y_test,logreg.predict(X_test)))\n",
    "print(accuracy_score(y_test,logreg.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing the classification report After logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        93\n",
      "           1       1.00      0.87      0.93        46\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       139\n",
      "   macro avg       0.97      0.93      0.95       139\n",
      "weighted avg       0.96      0.96      0.96       139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,logreg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing 10-fold cross validation on correctly classified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9527597402597403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\shara\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kf = KFold(n_splits=10) \n",
    "# kfold = KFold(n_splits=10, random_state=10) \n",
    "score = cross_val_score(logreg, X, y, cv=kf, scoring='accuracy').mean()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Naive Baye's on correctly classified Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 139 points : 3, performance 97.84%\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Number of mislabeled points out of a total {} points : {}, performance {:05.2f}%\"\n",
    "      .format(\n",
    "          X_test.shape[0],\n",
    "          (y_test != y_pred).sum(),\n",
    "          100*(1-(y_test!= y_pred).sum()/X_test.shape[0])\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98        93\n",
      "           1       0.96      0.98      0.97        46\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       139\n",
      "   macro avg       0.97      0.98      0.98       139\n",
      "weighted avg       0.98      0.98      0.98       139\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,gnb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID     Prediction_Value\n",
      "434    0\n",
      "466    1\n",
      "53     0\n",
      "250    0\n",
      "514    0\n",
      "179    0\n",
      "613    1\n",
      "227    0\n",
      "601    1\n",
      "280    1\n",
      "358    0\n",
      "76     0\n",
      "619    1\n",
      "472    1\n",
      "117    0\n",
      "317    0\n",
      "387    0\n",
      "302    0\n",
      "13     0\n",
      "41     0\n",
      "506    1\n",
      "492    1\n",
      "295    0\n",
      "304    0\n",
      "490    1\n",
      "191    0\n",
      "255    0\n",
      "504    1\n",
      "134    1\n",
      "151    0\n",
      "      ..\n",
      "196    0\n",
      "133    1\n",
      "207    0\n",
      "607    0\n",
      "21     0\n",
      "349    0\n",
      "616    1\n",
      "640    1\n",
      "57     0\n",
      "88     0\n",
      "565    0\n",
      "263    0\n",
      "500    0\n",
      "69     0\n",
      "435    0\n",
      "229    0\n",
      "603    1\n",
      "224    0\n",
      "63     0\n",
      "260    0\n",
      "628    1\n",
      "488    0\n",
      "587    1\n",
      "67     0\n",
      "14     0\n",
      "684    1\n",
      "445    0\n",
      "407    0\n",
      "493    1\n",
      "576    1\n",
      "Name: Outcome, Length: 139, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"ID    \", \"Prediction_Value\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
